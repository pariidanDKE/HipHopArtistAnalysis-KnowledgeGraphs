{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia-api in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from wikipedia-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from requests->wikipedia-api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from requests->wikipedia-api) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from requests->wikipedia-api) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danpa\\pycharmprojects\\bmkg_project\\venv\\lib\\site-packages (from requests->wikipedia-api) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia\n",
    "!pip install wikipedia-api\n",
    "!pip install transformers --quiet\n",
    "!pip install accelerate --quiet\n",
    "!pip install bitsandbytes --quiet\n",
    "!pip install langchain --quiet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:01.896407200Z",
     "start_time": "2024-03-16T12:38:44.819416500Z"
    }
   },
   "id": "e7c5e99e1c728c8e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danpa\\AppData\\Local\\Temp\\ipykernel_27436\\1718568720.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from HelperMethods import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:02.212030600Z",
     "start_time": "2024-03-16T12:39:01.897404700Z"
    }
   },
   "id": "74cd933056cff61d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import HelperMethods\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "importlib.reload(HelperMethods)\n",
    "from HelperMethods import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:02.226036400Z",
     "start_time": "2024-03-16T12:39:02.212030600Z"
    }
   },
   "id": "ae85f7f4d7c16fbd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bilboard Hot 100 data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3804f58952a813b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "charts_df = pd.read_csv('Data//charts.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:02.461145200Z",
     "start_time": "2024-03-16T12:39:02.227156500Z"
    }
   },
   "id": "46e76e346e65f0cd"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "              date  rank                                 song  \\\n0       2021-11-06     1                           Easy On Me   \n1       2021-11-06     2                                 Stay   \n2       2021-11-06     3                        Industry Baby   \n3       2021-11-06     4                           Fancy Like   \n4       2021-11-06     5                           Bad Habits   \n...            ...   ...                                  ...   \n330082  1958-08-04    96                        Over And Over   \n330083  1958-08-04    97                     I Believe In You   \n330084  1958-08-04    98                      Little Serenade   \n330085  1958-08-04    99  I'll Get By (As Long As I Have You)   \n330086  1958-08-04   100                                 Judy   \n\n                               Artist  last-week  peak-rank  weeks-on-board  \n0                               Adele        1.0          1               3  \n1       The Kid LAROI & Justin Bieber        2.0          1              16  \n2             Lil Nas X & Jack Harlow        3.0          1              14  \n3                        Walker Hayes        4.0          3              19  \n4                          Ed Sheeran        5.0          2              18  \n...                               ...        ...        ...             ...  \n330082                Thurston Harris        NaN         96               1  \n330083                Robert & Johnny        NaN         97               1  \n330084              The Ames Brothers        NaN         98               1  \n330085                 Billy Williams        NaN         99               1  \n330086                Frankie Vaughan        NaN        100               1  \n\n[330087 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>rank</th>\n      <th>song</th>\n      <th>Artist</th>\n      <th>last-week</th>\n      <th>peak-rank</th>\n      <th>weeks-on-board</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-11-06</td>\n      <td>1</td>\n      <td>Easy On Me</td>\n      <td>Adele</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-11-06</td>\n      <td>2</td>\n      <td>Stay</td>\n      <td>The Kid LAROI &amp; Justin Bieber</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-11-06</td>\n      <td>3</td>\n      <td>Industry Baby</td>\n      <td>Lil Nas X &amp; Jack Harlow</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-11-06</td>\n      <td>4</td>\n      <td>Fancy Like</td>\n      <td>Walker Hayes</td>\n      <td>4.0</td>\n      <td>3</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-11-06</td>\n      <td>5</td>\n      <td>Bad Habits</td>\n      <td>Ed Sheeran</td>\n      <td>5.0</td>\n      <td>2</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330082</th>\n      <td>1958-08-04</td>\n      <td>96</td>\n      <td>Over And Over</td>\n      <td>Thurston Harris</td>\n      <td>NaN</td>\n      <td>96</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>330083</th>\n      <td>1958-08-04</td>\n      <td>97</td>\n      <td>I Believe In You</td>\n      <td>Robert &amp; Johnny</td>\n      <td>NaN</td>\n      <td>97</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>330084</th>\n      <td>1958-08-04</td>\n      <td>98</td>\n      <td>Little Serenade</td>\n      <td>The Ames Brothers</td>\n      <td>NaN</td>\n      <td>98</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>330085</th>\n      <td>1958-08-04</td>\n      <td>99</td>\n      <td>I'll Get By (As Long As I Have You)</td>\n      <td>Billy Williams</td>\n      <td>NaN</td>\n      <td>99</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>330086</th>\n      <td>1958-08-04</td>\n      <td>100</td>\n      <td>Judy</td>\n      <td>Frankie Vaughan</td>\n      <td>NaN</td>\n      <td>100</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>330087 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charts_df.rename(columns={'artist': 'Artist'}, inplace=True)\n",
    "charts_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:02.478578100Z",
     "start_time": "2024-03-16T12:39:02.468102400Z"
    }
   },
   "id": "a0f9d73718f9492b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make the dataset smaller, only keep Top 10 entries for each week (reduce dataset by 90%)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10e074e41311227f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danpa\\AppData\\Local\\Temp\\ipykernel_27436\\2697134398.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top_10_each_week = charts_df.groupby('date').apply(lambda x: x.nsmallest(10, 'rank')).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "             date  rank               song  \\\n0      1958-08-04     1   Poor Little Fool   \n1      1958-08-04     2           Patricia   \n2      1958-08-04     3      Splish Splash   \n3      1958-08-04     4  Hard Headed Woman   \n4      1958-08-04     5               When   \n...           ...   ...                ...   \n33005  2021-11-06     6         Way 2 Sexy   \n33006  2021-11-06     7            Shivers   \n33007  2021-11-06     8           Good 4 U   \n33008  2021-11-06     9       Need To Know   \n33009  2021-11-06    10         Levitating   \n\n                                    Artist  last-week  peak-rank  \\\n0                             Ricky Nelson        NaN          1   \n1            Perez Prado And His Orchestra        NaN          2   \n2                              Bobby Darin        NaN          3   \n3       Elvis Presley With The Jordanaires        NaN          4   \n4                              Kalin Twins        NaN          5   \n...                                    ...        ...        ...   \n33005  Drake Featuring Future & Young Thug        6.0          1   \n33006                           Ed Sheeran        9.0          7   \n33007                       Olivia Rodrigo        7.0          1   \n33008                             Doja Cat       11.0          9   \n33009                             Dua Lipa        8.0          2   \n\n       weeks-on-board  \n0                   1  \n1                   1  \n2                   1  \n3                   1  \n4                   1  \n...               ...  \n33005               8  \n33006               7  \n33007              24  \n33008              20  \n33009              56  \n\n[33010 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>rank</th>\n      <th>song</th>\n      <th>Artist</th>\n      <th>last-week</th>\n      <th>peak-rank</th>\n      <th>weeks-on-board</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1958-08-04</td>\n      <td>1</td>\n      <td>Poor Little Fool</td>\n      <td>Ricky Nelson</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1958-08-04</td>\n      <td>2</td>\n      <td>Patricia</td>\n      <td>Perez Prado And His Orchestra</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1958-08-04</td>\n      <td>3</td>\n      <td>Splish Splash</td>\n      <td>Bobby Darin</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1958-08-04</td>\n      <td>4</td>\n      <td>Hard Headed Woman</td>\n      <td>Elvis Presley With The Jordanaires</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1958-08-04</td>\n      <td>5</td>\n      <td>When</td>\n      <td>Kalin Twins</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33005</th>\n      <td>2021-11-06</td>\n      <td>6</td>\n      <td>Way 2 Sexy</td>\n      <td>Drake Featuring Future &amp; Young Thug</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>33006</th>\n      <td>2021-11-06</td>\n      <td>7</td>\n      <td>Shivers</td>\n      <td>Ed Sheeran</td>\n      <td>9.0</td>\n      <td>7</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>33007</th>\n      <td>2021-11-06</td>\n      <td>8</td>\n      <td>Good 4 U</td>\n      <td>Olivia Rodrigo</td>\n      <td>7.0</td>\n      <td>1</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>33008</th>\n      <td>2021-11-06</td>\n      <td>9</td>\n      <td>Need To Know</td>\n      <td>Doja Cat</td>\n      <td>11.0</td>\n      <td>9</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>33009</th>\n      <td>2021-11-06</td>\n      <td>10</td>\n      <td>Levitating</td>\n      <td>Dua Lipa</td>\n      <td>8.0</td>\n      <td>2</td>\n      <td>56</td>\n    </tr>\n  </tbody>\n</table>\n<p>33010 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_each_week = charts_df.groupby('date').apply(lambda x: x.nsmallest(10, 'rank')).reset_index(drop=True)\n",
    "# To display the result or work with it further\n",
    "top_10_each_week.sort_values(by=['date', 'rank'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:05.496073400Z",
     "start_time": "2024-03-16T12:39:02.479579400Z"
    }
   },
   "id": "7df21f27a6a3952d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Ricky Nelson', 'Perez Prado And His Orchestra', 'Bobby Darin',\n       ..., 'Coldplay x BTS', 'Wizkid Featuring Justin Bieber & Tems',\n       'Doja Cat'], dtype=object)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_each_week['Artist'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:05.539660200Z",
     "start_time": "2024-03-16T12:39:05.498111200Z"
    }
   },
   "id": "f732b967cc498127"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The artist column contains multiple artists in one string, this is not ideal for analysis, we will split the arits into multiple columns (Artist1, Artist2, Artist3, etc.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56f1b510065231d3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "separated_artists = []\n",
    "\n",
    "for artist in top_10_each_week['Artist'].unique():\n",
    "    separated_artists.append(separate_artists(artist))\n",
    "\n",
    "for i in range(1,6):\n",
    "    top_10_each_week['Artists'+str(i)] = np.nan  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:05.587148100Z",
     "start_time": "2024-03-16T12:39:05.512793400Z"
    }
   },
   "id": "68e1d27d8c7a6483"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# in the loop , 'Arist'+i as the name of the column to add this artist in\n",
    "for idx,row in top_10_each_week.iterrows():\n",
    "    artists = separate_artists(row['Artist'])\n",
    "    for i, artist in enumerate(artists):\n",
    "        top_10_each_week.at[idx, 'Artist'+str(i+1)] = artist"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:08.151701400Z",
     "start_time": "2024-03-16T12:39:05.543648400Z"
    }
   },
   "id": "85ad42eb770999bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_10_each_week[['Artist','Artist1', 'Artist2', 'Artist3', 'Artist4', 'Artist5']] \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f91f95e02a8e94c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#top_10_each_week.to_csv('Data//charts10.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e5d7c036360b1d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data on best selling artists and how much they sold."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9932096458170c59"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "artist_df = pd.read_csv('Data//best_selling_artists.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:08.206805700Z",
     "start_time": "2024-03-16T12:39:08.168656400Z"
    }
   },
   "id": "efdce0ac685da9b8"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "40f0f788465019f2"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "artist_df['Artist'] = artist_df['Artist'].replace({'Beyoncé': 'Beyonce', 'Jay-Z': 'Jay Z', 'Pink': 'P!nk', 'B\\'z': 'Bz', 'Julio Iglesias': 'Julio Iglesias Jr.', 'The Carpenters': 'Carpenters', 'Ayumi Hamasaki': 'Hamasaki Ayumi', 'Johnny Hallyday': 'Hallyday Johnny', 'Tupac Shakur': '2Pac', 'Bob Marley': 'Bob Marley & The Wailers'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:08.242741400Z",
     "start_time": "2024-03-16T12:39:08.186348300Z"
    }
   },
   "id": "ff0a79cbbc056254"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "38d7a55e728747ab"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "artist_df = artist_df.loc[artist_df['Artist'].isin(top_10_each_week[['Artist1','Artist2','Artist3','Artist4','Artist5']].values.flatten())]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:08.307117Z",
     "start_time": "2024-03-16T12:39:08.203819Z"
    }
   },
   "id": "1f71ee99601bc361"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get Information on Personal Life,Family of artists"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "108a32e649c2981b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Beatles' 'Elvis Presley' 'Michael Jackson' 'Elton John' 'Queen'\n",
      " 'Madonna' 'Led Zeppelin' 'Rihanna' 'Pink Floyd' 'Eminem' 'Mariah Carey'\n",
      " 'Taylor Swift' 'Beyonce' 'Whitney Houston' 'Eagles' 'Celine Dion'\n",
      " 'The Rolling Stones' 'Drake' 'Kanye West' 'Billy Joel' 'Justin Bieber'\n",
      " 'Ed Sheeran' 'Bruno Mars' 'Bruce Springsteen' 'U2' 'Aerosmith'\n",
      " 'Phil Collins' 'Barbra Streisand' 'ABBA' 'Frank Sinatra' 'Katy Perry'\n",
      " 'Chris Brown' 'Jay Z' 'Metallica' 'Lady Gaga' 'Lil Wayne' 'Maroon 5'\n",
      " 'Adele' 'Red Hot Chili Peppers' 'Fleetwood Mac' 'Bon Jovi' 'Rod Stewart'\n",
      " 'Bee Gees' 'Nicki Minaj' 'Coldplay' 'Linkin Park' 'P!nk' 'Britney Spears'\n",
      " 'Shania Twain' \"Guns N' Roses\" 'Backstreet Boys' 'Eric Clapton'\n",
      " 'Neil Diamond' 'Prince' 'Journey' 'Paul McCartney' 'Janet Jackson'\n",
      " 'Kenny Rogers' 'Santana' 'George Michael' 'Dire Straits' 'The Doors'\n",
      " 'Foreigner' 'Chicago' 'Bob Dylan' 'Carpenters' 'Meat Loaf' 'Cher'\n",
      " 'Def Leppard' 'Genesis' 'David Bowie' 'Stevie Wonder' 'James Taylor'\n",
      " 'Tina Turner' 'Olivia Newton-John' 'Linda Ronstadt' 'The Beach Boys'\n",
      " 'Donna Summer' 'Alicia Keys' 'Christina Aguilera' 'Lionel Richie'\n",
      " 'Johnny Cash' 'Justin Timberlake' 'Ariana Grande' 'R.E.M.' 'Post Malone'\n",
      " 'Flo Rida' 'Usher' 'Shakira' 'Tim McGraw' 'The Black Eyed Peas'\n",
      " 'Van Halen' 'Tom Petty' 'The Weeknd' 'Imagine Dragons' '2Pac' 'R. Kelly'\n",
      " 'Nirvana' 'Bob Seger' 'Kenny G' 'Green Day' 'Enya' 'Bryan Adams'\n",
      " 'The Police' 'Gloria Estefan' 'Barry Manilow' 'Aretha Franklin']\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "from rdflib import Graph, URIRef, Literal\n",
    "print(artist_df['Artist'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:39:08.331217600Z",
     "start_time": "2024-03-16T12:39:08.234729900Z"
    }
   },
   "id": "4526be62981f9034"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "\n",
    "def send_relatives_request(artist_uri,properties,repo):\n",
    "    \n",
    "    results_dict = {v: [] for k, v in properties.items()}\n",
    "    # Madonna's Wikidata item\n",
    "    item = pywikibot.ItemPage(repo, artist_uri)\n",
    "    \n",
    "    # Fetch the item's data\n",
    "    item.get()\n",
    "\n",
    "    # Iterate through the specified properties\n",
    "    for prop in properties:\n",
    "        if prop in item.claims:\n",
    "            #print(f\"{properties[prop]}:\")\n",
    "            for claim in item.claims[prop]:\n",
    "                # The target is the family member's item\n",
    "                target = claim.getTarget()\n",
    "                print(target)\n",
    "                \n",
    "                if isinstance(target, pywikibot.ItemPage):       \n",
    "                    target.get()\n",
    "                    #print(f\"  {target.labels['en']}\")\n",
    "                    results_dict[properties[prop]].append(target.labels['en'])\n",
    "\n",
    "                        \n",
    "    return results_dict      "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T13:09:58.992796200Z",
     "start_time": "2024-03-16T13:09:58.974329700Z"
    }
   },
   "id": "18a1bd9d79945b19"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "### DONT RUN THIS CELL, IT TAKES A LONG TIME TO FILL celebrity_uri_dict\n",
    "\n",
    "celebrity_uri_dict = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-15T10:45:13.811670200Z"
    }
   },
   "id": "f32313a4a5fa1eaf"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for entity with label 'The Beatles'..\n",
      "Found URI for 'The Beatles': Q1299\n",
      "Searching for entity with label 'Elvis Presley'..\n",
      "Found URI for 'Elvis Presley': Q303\n",
      "Searching for entity with label 'Michael Jackson'..\n",
      "Found URI for 'Michael Jackson': Q2831\n",
      "Searching for entity with label 'Elton John'..\n",
      "Found URI for 'Elton John': Q2808\n",
      "Searching for entity with label 'Queen(band)'..\n",
      "No entity found for label 'Queen(band)' in language 'en'.\n",
      "Searching for entity with label 'Madonna'..\n",
      "Found URI for 'Madonna': Q345\n",
      "Searching for entity with label 'Led Zeppelin'..\n",
      "Found URI for 'Led Zeppelin': Q2331\n",
      "Searching for entity with label 'Rihanna'..\n",
      "Found URI for 'Rihanna': Q36844\n",
      "Searching for entity with label 'Pink Floyd'..\n",
      "Found URI for 'Pink Floyd': Q2306\n",
      "Searching for entity with label 'Eminem'..\n",
      "Found URI for 'Eminem': Q5608\n",
      "Searching for entity with label 'Mariah Carey'..\n",
      "Found URI for 'Mariah Carey': Q41076\n",
      "Searching for entity with label 'Taylor Swift'..\n",
      "Found URI for 'Taylor Swift': Q26876\n",
      "Searching for entity with label 'Beyonce'..\n",
      "Found URI for 'Beyonce': Q36153\n",
      "Searching for entity with label 'Whitney Houston'..\n",
      "Found URI for 'Whitney Houston': Q34389\n",
      "Searching for entity with label 'Eagles'..\n",
      "Found URI for 'Eagles': Q219714\n",
      "Searching for entity with label 'Celine Dion'..\n",
      "Found URI for 'Celine Dion': Q5105\n",
      "Searching for entity with label 'The Rolling Stones'..\n",
      "Found URI for 'The Rolling Stones': Q11036\n",
      "Searching for entity with label 'Drake'..\n",
      "Found URI for 'Drake': Q7559\n",
      "Searching for entity with label 'Kanye West'..\n",
      "Found URI for 'Kanye West': Q15935\n",
      "Searching for entity with label 'Billy Joel'..\n",
      "Found URI for 'Billy Joel': Q194333\n",
      "Searching for entity with label 'Justin Bieber'..\n",
      "Found URI for 'Justin Bieber': Q34086\n",
      "Searching for entity with label 'Ed Sheeran'..\n",
      "Found URI for 'Ed Sheeran': Q47447\n",
      "Searching for entity with label 'Bruno Mars'..\n",
      "Found URI for 'Bruno Mars': Q1450\n",
      "Searching for entity with label 'Bruce Springsteen'..\n",
      "Found URI for 'Bruce Springsteen': Q1225\n",
      "Searching for entity with label 'U2'..\n",
      "Found URI for 'U2': Q396\n",
      "Searching for entity with label 'Aerosmith'..\n",
      "Found URI for 'Aerosmith': Q126826\n",
      "Searching for entity with label 'Phil Collins'..\n",
      "Found URI for 'Phil Collins': Q144622\n",
      "Searching for entity with label 'Barbra Streisand'..\n",
      "Found URI for 'Barbra Streisand': Q4636\n",
      "Searching for entity with label 'ABBA'..\n",
      "Found URI for 'ABBA': Q18233\n",
      "Searching for entity with label 'Frank Sinatra'..\n",
      "Found URI for 'Frank Sinatra': Q40912\n",
      "Searching for entity with label 'Katy Perry'..\n",
      "Found URI for 'Katy Perry': Q42493\n",
      "Searching for entity with label 'Chris Brown'..\n",
      "Found URI for 'Chris Brown': Q155700\n",
      "Searching for entity with label 'Jay Z'..\n",
      "Found URI for 'Jay Z': Q62766\n",
      "Searching for entity with label 'Metallica'..\n",
      "Found URI for 'Metallica': Q15920\n",
      "Searching for entity with label 'Lady Gaga'..\n",
      "Found URI for 'Lady Gaga': Q19848\n",
      "Searching for entity with label 'Lil Wayne'..\n",
      "Found URI for 'Lil Wayne': Q15615\n",
      "Searching for entity with label 'Maroon 5'..\n",
      "Found URI for 'Maroon 5': Q182223\n",
      "Searching for entity with label 'Adele'..\n",
      "Found URI for 'Adele': Q23215\n",
      "Searching for entity with label 'Red Hot Chili Peppers'..\n",
      "Found URI for 'Red Hot Chili Peppers': Q10708\n",
      "Searching for entity with label 'Fleetwood Mac'..\n",
      "Found URI for 'Fleetwood Mac': Q106648\n",
      "Searching for entity with label 'Bon Jovi'..\n",
      "Found URI for 'Bon Jovi': Q259254\n",
      "Searching for entity with label 'Rod Stewart'..\n",
      "Found URI for 'Rod Stewart': Q182655\n",
      "Searching for entity with label 'Bee Gees'..\n",
      "Found URI for 'Bee Gees': Q133405\n",
      "Searching for entity with label 'Nicki Minaj'..\n",
      "Found URI for 'Nicki Minaj': Q162202\n",
      "Searching for entity with label 'Coldplay'..\n",
      "Found URI for 'Coldplay': Q45188\n",
      "Searching for entity with label 'Linkin Park'..\n",
      "Found URI for 'Linkin Park': Q261\n",
      "Searching for entity with label 'P!nk'..\n",
      "Found URI for 'P!nk': Q160009\n",
      "Searching for entity with label 'Britney Spears'..\n",
      "Found URI for 'Britney Spears': Q11975\n",
      "Searching for entity with label 'Shania Twain'..\n",
      "Found URI for 'Shania Twain': Q131433\n",
      "Searching for entity with label 'Guns N' Roses'..\n",
      "Found URI for 'Guns N' Roses': Q11895\n",
      "Searching for entity with label 'Backstreet Boys'..\n",
      "Found URI for 'Backstreet Boys': Q17140\n",
      "Searching for entity with label 'Eric Clapton'..\n",
      "Found URI for 'Eric Clapton': Q48187\n",
      "Searching for entity with label 'Neil Diamond'..\n",
      "Found URI for 'Neil Diamond': Q294531\n",
      "Searching for entity with label 'Prince'..\n",
      "Found URI for 'Prince': Q2747456\n",
      "Searching for entity with label 'Journey'..\n",
      "Found URI for 'Journey': Q61509\n",
      "Searching for entity with label 'Paul McCartney'..\n",
      "Found URI for 'Paul McCartney': Q2599\n",
      "Searching for entity with label 'Janet Jackson'..\n",
      "Found URI for 'Janet Jackson': Q131324\n",
      "Searching for entity with label 'Kenny Rogers'..\n",
      "Found URI for 'Kenny Rogers': Q217160\n",
      "Searching for entity with label 'Santana'..\n",
      "Found URI for 'Santana': Q873384\n",
      "Searching for entity with label 'George Michael'..\n",
      "Found URI for 'George Michael': Q130311\n",
      "Searching for entity with label 'Dire Straits'..\n",
      "Found URI for 'Dire Straits': Q50040\n",
      "Searching for entity with label 'The Doors'..\n",
      "Found URI for 'The Doors': Q45354\n",
      "Searching for entity with label 'Foreigner'..\n",
      "Found URI for 'Foreigner': Q473741\n",
      "Searching for entity with label 'Chicago'..\n",
      "Found URI for 'Chicago': Q1297\n",
      "Searching for entity with label 'Bob Dylan'..\n",
      "Found URI for 'Bob Dylan': Q392\n",
      "Searching for entity with label 'Carpenters'..\n",
      "Found URI for 'Carpenters': Q223495\n",
      "Searching for entity with label 'Meat Loaf'..\n",
      "Found URI for 'Meat Loaf': Q152929\n",
      "Searching for entity with label 'Cher'..\n",
      "Found URI for 'Cher': Q3286\n",
      "Searching for entity with label 'Def Leppard'..\n",
      "Found URI for 'Def Leppard': Q182890\n",
      "Searching for entity with label 'Genesis'..\n",
      "Found URI for 'Genesis': Q9184\n",
      "Searching for entity with label 'David Bowie'..\n",
      "Found URI for 'David Bowie': Q5383\n",
      "Searching for entity with label 'Stevie Wonder'..\n",
      "Found URI for 'Stevie Wonder': Q714\n",
      "Searching for entity with label 'James Taylor'..\n",
      "Found URI for 'James Taylor': Q310300\n",
      "Searching for entity with label 'Tina Turner'..\n",
      "Found URI for 'Tina Turner': Q131814\n",
      "Searching for entity with label 'Olivia Newton-John'..\n",
      "Found URI for 'Olivia Newton-John': Q185165\n",
      "Searching for entity with label 'Linda Ronstadt'..\n",
      "Found URI for 'Linda Ronstadt': Q229375\n",
      "Searching for entity with label 'The Beach Boys'..\n",
      "Found URI for 'The Beach Boys': Q183048\n",
      "Searching for entity with label 'Donna Summer'..\n",
      "Found URI for 'Donna Summer': Q908933\n",
      "Searching for entity with label 'Alicia Keys'..\n",
      "Found URI for 'Alicia Keys': Q121507\n",
      "Searching for entity with label 'Christina Aguilera'..\n",
      "Found URI for 'Christina Aguilera': Q41594\n",
      "Searching for entity with label 'Lionel Richie'..\n",
      "Found URI for 'Lionel Richie': Q26695\n",
      "Searching for entity with label 'Johnny Cash'..\n",
      "Found URI for 'Johnny Cash': Q42775\n",
      "Searching for entity with label 'Justin Timberlake'..\n",
      "Found URI for 'Justin Timberlake': Q43432\n",
      "Searching for entity with label 'Ariana Grande'..\n",
      "Found URI for 'Ariana Grande': Q151892\n",
      "Searching for entity with label 'R.E.M.'..\n",
      "Found URI for 'R.E.M.': Q134969\n",
      "Searching for entity with label 'Post Malone'..\n",
      "Found URI for 'Post Malone': Q21621919\n",
      "Searching for entity with label 'Flo Rida'..\n",
      "Found URI for 'Flo Rida': Q213538\n",
      "Searching for entity with label 'Usher'..\n",
      "Found URI for 'Usher': Q165911\n",
      "Searching for entity with label 'Shakira'..\n",
      "Found URI for 'Shakira': Q34424\n",
      "Searching for entity with label 'Tim McGraw'..\n",
      "Found URI for 'Tim McGraw': Q356487\n",
      "Searching for entity with label 'The Black Eyed Peas'..\n",
      "Found URI for 'The Black Eyed Peas': Q134541\n",
      "Searching for entity with label 'Van Halen'..\n",
      "Found URI for 'Van Halen': Q190155\n",
      "Searching for entity with label 'Tom Petty'..\n",
      "Found URI for 'Tom Petty': Q311655\n",
      "Searching for entity with label 'The Weeknd'..\n",
      "Found URI for 'The Weeknd': Q2121062\n",
      "Searching for entity with label 'Imagine Dragons'..\n",
      "Found URI for 'Imagine Dragons': Q391348\n",
      "Searching for entity with label '2Pac'..\n",
      "Found URI for '2Pac': Q6107\n",
      "Searching for entity with label 'R. Kelly'..\n",
      "Found URI for 'R. Kelly': Q273055\n",
      "Searching for entity with label 'Nirvana'..\n",
      "Found URI for 'Nirvana': Q11649\n",
      "Searching for entity with label 'Bob Seger'..\n",
      "Found URI for 'Bob Seger': Q364131\n",
      "Searching for entity with label 'Kenny G'..\n",
      "Found URI for 'Kenny G': Q295777\n",
      "Searching for entity with label 'Green Day'..\n",
      "Found URI for 'Green Day': Q47871\n",
      "Searching for entity with label 'Enya'..\n",
      "Found URI for 'Enya': Q38257\n",
      "Searching for entity with label 'Bryan Adams'..\n",
      "Found URI for 'Bryan Adams': Q482907\n",
      "Searching for entity with label 'The Police'..\n",
      "Found URI for 'The Police': Q178095\n",
      "Searching for entity with label 'Gloria Estefan'..\n",
      "Found URI for 'Gloria Estefan': Q184697\n",
      "Searching for entity with label 'Barry Manilow'..\n",
      "Found URI for 'Barry Manilow': Q302762\n",
      "Searching for entity with label 'Aretha Franklin'..\n",
      "Found URI for 'Aretha Franklin': Q125121\n"
     ]
    }
   ],
   "source": [
    "import pywikibot\n",
    "from pywikibot import Site\n",
    "\n",
    "def search_entity_uri_by_label(label, language='en'):\n",
    "    \"\"\"\n",
    "    Search for a Wikidata entity by its label and return its URI.\n",
    "    \n",
    "    Parameters:\n",
    "    - label: The label of the entity to search for.\n",
    "    - language: The language of the label (default is 'en' for English).\n",
    "    \n",
    "    Returns:\n",
    "    The URI of the found entity, or None if not found.\n",
    "    \"\"\"\n",
    "    # Connect to Wikidata\n",
    "    wikidata_site = Site(\"wikidata\", \"wikidata\")\n",
    "    repo = wikidata_site.data_repository()\n",
    "    \n",
    "    # Search for entities by label\n",
    "    search_results = list(repo.search_entities(label, language))\n",
    "    \n",
    "    if not search_results:\n",
    "        print(f\"No entity found for label '{label}' in language '{language}'.\")\n",
    "        return None\n",
    "    \n",
    "    # Assuming we take the first search result\n",
    "    first_result = search_results[0]\n",
    "    entity_id = first_result['id']\n",
    "    \n",
    "    # Construct the URI\n",
    "    uri = entity_id\n",
    "    \n",
    "    return uri\n",
    "\n",
    "# Example usage\n",
    "labels =  artist_df['Artist'].unique()\n",
    "labels[4] = 'Queen(band)'\n",
    "\n",
    "#celebrity_uri_dict = {}\n",
    "\n",
    "for label in labels:\n",
    "    print(f\"Searching for entity with label '{label}'..\")\n",
    "    uri = search_entity_uri_by_label(label)    \n",
    "    celebrity_uri_dict[label] = uri\n",
    "    \n",
    "    if uri:\n",
    "        print(f\"Found URI for '{label}': {uri}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T17:18:07.414539200Z",
     "start_time": "2024-03-15T16:21:41.650587900Z"
    }
   },
   "id": "c2b3bb3b9352b1da"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import pywikibot\n",
    "import ast\n",
    "\n",
    "\n",
    "site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "repo = site.data_repository()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:41:32.932403300Z",
     "start_time": "2024-03-16T12:41:31.024699500Z"
    }
   },
   "id": "e1404a41873f325b"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "## URI take long time so saved the file\n",
    "with open('Data//artisturis.txt', 'r') as file:\n",
    "    # Read the file content\n",
    "    file_content = file.read()\n",
    "    # Safely evaluate the string as a Python expression\n",
    "    celebrity_uri_dict = ast.literal_eval(file_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T13:01:53.917010Z",
     "start_time": "2024-03-16T13:01:53.812058700Z"
    }
   },
   "id": "d1abe07338172fb9"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# properties that i want to extract per Artist\n",
    "properties = {\n",
    "        # 'P22': 'Father',\n",
    "        # 'P25': 'Mother',\n",
    "        'P40': 'Children',\n",
    "        'P26': 'Spouse',\n",
    "        'P3373': 'Siblings',\n",
    "        'P264': 'RecordLabel',\n",
    "\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T13:01:58.512706800Z",
     "start_time": "2024-03-16T13:01:58.498744400Z"
    }
   },
   "id": "5da22cd18431d9eb"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching relatives for The Beatles (Q1299)..\n",
      "Fetching relatives for Elvis Presley (Q303)..\n",
      "Fetching relatives for Michael Jackson (Q2831)..\n",
      "Fetching relatives for Elton John (Q2808)..\n",
      "Fetching relatives for Queen(band) (Q15862)..\n",
      "Fetching relatives for Madonna (Q345)..\n",
      "Fetching relatives for Led Zeppelin (Q2331)..\n",
      "Fetching relatives for Rihanna (Q36844)..\n",
      "Fetching relatives for Pink Floyd (Q2306)..\n",
      "Fetching relatives for Eminem (Q5608)..\n",
      "Fetching relatives for Mariah Carey (Q41076)..\n",
      "Fetching relatives for Taylor Swift (Q26876)..\n",
      "Fetching relatives for Beyonce (Q36153)..\n",
      "Fetching relatives for Whitney Houston (Q34389)..\n",
      "Fetching relatives for Eagles (Q219714)..\n",
      "Fetching relatives for Celine Dion (Q5105)..\n",
      "Fetching relatives for The Rolling Stones (Q11036)..\n",
      "Fetching relatives for Drake (Q7559)..\n",
      "Fetching relatives for Kanye West (Q15935)..\n",
      "Fetching relatives for Billy Joel (Q194333)..\n",
      "Fetching relatives for Justin Bieber (Q34086)..\n",
      "Fetching relatives for Ed Sheeran (Q47447)..\n",
      "Fetching relatives for Bruno Mars (Q1450)..\n",
      "Fetching relatives for Bruce Springsteen (Q1225)..\n",
      "Fetching relatives for U2 (Q396)..\n",
      "Fetching relatives for Aerosmith (Q126826)..\n",
      "Fetching relatives for Phil Collins (Q144622)..\n",
      "Fetching relatives for Barbra Streisand (Q4636)..\n",
      "Fetching relatives for ABBA (Q18233)..\n",
      "Fetching relatives for Frank Sinatra (Q40912)..\n",
      "Fetching relatives for Katy Perry (Q42493)..\n",
      "Fetching relatives for Chris Brown (Q155700)..\n",
      "Fetching relatives for Jay Z (Q62766)..\n",
      "Fetching relatives for Metallica (Q15920)..\n",
      "Fetching relatives for Lady Gaga (Q19848)..\n",
      "Fetching relatives for Lil Wayne (Q15615)..\n",
      "Fetching relatives for Maroon 5 (Q182223)..\n",
      "Fetching relatives for Adele (Q23215)..\n",
      "Fetching relatives for Red Hot Chili Peppers (Q10708)..\n",
      "Fetching relatives for Fleetwood Mac (Q106648)..\n",
      "Fetching relatives for Bon Jovi (Q259254)..\n",
      "Fetching relatives for Rod Stewart (Q182655)..\n",
      "Fetching relatives for Bee Gees (Q133405)..\n",
      "Fetching relatives for Nicki Minaj (Q162202)..\n",
      "Fetching relatives for Coldplay (Q45188)..\n",
      "Fetching relatives for Linkin Park (Q261)..\n",
      "Fetching relatives for P!nk (Q160009)..\n",
      "Fetching relatives for Britney Spears (Q11975)..\n",
      "Fetching relatives for Shania Twain (Q131433)..\n",
      "Fetching relatives for Guns N' Roses (Q11895)..\n",
      "Fetching relatives for Backstreet Boys (Q17140)..\n",
      "Fetching relatives for Eric Clapton (Q48187)..\n",
      "Fetching relatives for Neil Diamond (Q294531)..\n",
      "Fetching relatives for Prince (Q2747456)..\n",
      "Fetching relatives for Journey (Q61509)..\n",
      "Fetching relatives for Paul McCartney (Q2599)..\n",
      "Fetching relatives for Janet Jackson (Q131324)..\n",
      "Fetching relatives for Kenny Rogers (Q217160)..\n",
      "Fetching relatives for Santana (Q873384)..\n",
      "Fetching relatives for George Michael (Q130311)..\n",
      "Fetching relatives for Dire Straits (Q50040)..\n",
      "Fetching relatives for The Doors (Q45354)..\n",
      "Fetching relatives for Foreigner (Q473741)..\n",
      "Fetching relatives for Chicago (Q371938)..\n",
      "Fetching relatives for Bob Dylan (Q392)..\n",
      "Fetching relatives for Carpenters (Q223495)..\n",
      "Fetching relatives for Meat Loaf (Q152929)..\n",
      "Fetching relatives for Cher (Q3286)..\n",
      "Fetching relatives for Def Leppard (Q182890)..\n",
      "Fetching relatives for Genesis (Q9184)..\n",
      "Fetching relatives for David Bowie (Q5383)..\n",
      "Fetching relatives for Stevie Wonder (Q714)..\n",
      "Fetching relatives for James Taylor (Q310300)..\n",
      "Fetching relatives for Tina Turner (Q131814)..\n",
      "Fetching relatives for Olivia Newton-John (Q185165)..\n",
      "Fetching relatives for Linda Ronstadt (Q229375)..\n",
      "Fetching relatives for The Beach Boys (Q183048)..\n",
      "Fetching relatives for Donna Summer (Q908933)..\n",
      "Fetching relatives for Alicia Keys (Q121507)..\n",
      "Fetching relatives for Christina Aguilera (Q41594)..\n",
      "Fetching relatives for Lionel Richie (Q26695)..\n",
      "Fetching relatives for Johnny Cash (Q42775)..\n",
      "Fetching relatives for Justin Timberlake (Q43432)..\n",
      "Fetching relatives for Ariana Grande (Q151892)..\n",
      "Fetching relatives for R.E.M. (Q134969)..\n",
      "Fetching relatives for Post Malone (Q21621919)..\n",
      "Fetching relatives for Flo Rida (Q213538)..\n",
      "Fetching relatives for Usher (Q165911)..\n",
      "Fetching relatives for Shakira (Q34424)..\n",
      "Fetching relatives for Tim McGraw (Q356487)..\n",
      "Fetching relatives for The Black Eyed Peas (Q134541)..\n",
      "Fetching relatives for Van Halen (Q190155)..\n",
      "Fetching relatives for Tom Petty (Q311655)..\n",
      "Fetching relatives for The Weeknd (Q2121062)..\n",
      "Fetching relatives for Imagine Dragons (Q391348)..\n",
      "Fetching relatives for 2Pac (Q6107)..\n",
      "Fetching relatives for R. Kelly (Q273055)..\n",
      "Fetching relatives for Nirvana (Q11649)..\n",
      "Fetching relatives for Bob Seger (Q364131)..\n",
      "Fetching relatives for Kenny G (Q295777)..\n",
      "Fetching relatives for Green Day (Q47871)..\n",
      "Fetching relatives for Enya (Q38257)..\n",
      "Fetching relatives for Bryan Adams (Q482907)..\n",
      "Fetching relatives for The Police (Q178095)..\n",
      "Fetching relatives for Gloria Estefan (Q184697)..\n",
      "Fetching relatives for Barry Manilow (Q302762)..\n",
      "Fetching relatives for Aretha Franklin (Q125121)..\n"
     ]
    }
   ],
   "source": [
    "celebrity_relatives = {}\n",
    "# Iterate over each celebrity and fetch their relatives\n",
    "for celebrity, celebrity_uri in celebrity_uri_dict.items():\n",
    "    print(f\"Fetching relatives for {celebrity} ({celebrity_uri})..\")\n",
    "    results = send_relatives_request(celebrity_uri,properties,repo)\n",
    "    #print(results)\n",
    "    #print('*'*50)\n",
    "    celebrity_relatives[celebrity] = results\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T13:06:09.927572100Z",
     "start_time": "2024-03-16T13:01:59.407368900Z"
    }
   },
   "id": "1cf28f42674cc63a"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# import ast\n",
    "# \n",
    "# with open('Data//celebrity_relatives_dict(incomplete)', 'r') as file:\n",
    "#     # Read the file content\n",
    "#     file_content = file.read()\n",
    "#     # Safely evaluate the string as a Python expression\n",
    "#     celebrity_relatives = ast.literal_eval(file_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T13:00:34.718374600Z",
     "start_time": "2024-03-16T13:00:34.598850100Z"
    }
   },
   "id": "1bb43d9ae5c80a1f"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "'Q130311'"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subset_dict.pop('George Michael')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T12:56:04.747898700Z",
     "start_time": "2024-03-16T12:56:04.669875600Z"
    }
   },
   "id": "92519a6504e3510a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "celebrity_relatives_df = pd.DataFrame(celebrity_relatives).T\n",
    "celebrity_relatives_df.reset_index(inplace=True)\n",
    "celebrity_relatives_df.rename(columns={'index': 'Artist'}, inplace=True)\n",
    "#celebrity_relatives_df.to_csv('Data//celebrity_relatives&label.csv', index=False)\n",
    "celebrity_relatives_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4dc0f65891f397e"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T13:07:12.184146400Z",
     "start_time": "2024-03-16T13:07:12.099356300Z"
    }
   },
   "id": "d778269e6b3996a9"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching quantity properties for The Beatles (Q1299)..\n",
      "Fetching quantity properties for Elvis Presley (Q303)..\n",
      "Fetching quantity properties for Michael Jackson (Q2831)..\n",
      "Fetching quantity properties for Elton John (Q2808)..\n",
      "Fetching quantity properties for Queen(band) (Q15862)..\n",
      "Fetching quantity properties for Madonna (Q345)..\n",
      "Fetching quantity properties for Led Zeppelin (Q2331)..\n",
      "Fetching quantity properties for Rihanna (Q36844)..\n",
      "Fetching quantity properties for Pink Floyd (Q2306)..\n",
      "Fetching quantity properties for Eminem (Q5608)..\n",
      "Fetching quantity properties for Mariah Carey (Q41076)..\n",
      "Fetching quantity properties for Taylor Swift (Q26876)..\n",
      "Fetching quantity properties for Beyonce (Q36153)..\n",
      "Fetching quantity properties for Whitney Houston (Q34389)..\n",
      "Fetching quantity properties for Eagles (Q219714)..\n",
      "Fetching quantity properties for Celine Dion (Q5105)..\n",
      "Fetching quantity properties for The Rolling Stones (Q11036)..\n",
      "Fetching quantity properties for Drake (Q7559)..\n",
      "Fetching quantity properties for Kanye West (Q15935)..\n",
      "Fetching quantity properties for Billy Joel (Q194333)..\n",
      "Fetching quantity properties for Justin Bieber (Q34086)..\n",
      "Fetching quantity properties for Ed Sheeran (Q47447)..\n",
      "Fetching quantity properties for Bruno Mars (Q1450)..\n",
      "Fetching quantity properties for Bruce Springsteen (Q1225)..\n",
      "Fetching quantity properties for U2 (Q396)..\n",
      "Fetching quantity properties for Aerosmith (Q126826)..\n",
      "Fetching quantity properties for Phil Collins (Q144622)..\n",
      "Fetching quantity properties for Barbra Streisand (Q4636)..\n",
      "Fetching quantity properties for ABBA (Q18233)..\n",
      "Fetching quantity properties for Frank Sinatra (Q40912)..\n",
      "Fetching quantity properties for Katy Perry (Q42493)..\n",
      "Fetching quantity properties for Chris Brown (Q155700)..\n",
      "Fetching quantity properties for Jay Z (Q62766)..\n",
      "Fetching quantity properties for Metallica (Q15920)..\n",
      "Fetching quantity properties for Lady Gaga (Q19848)..\n",
      "Fetching quantity properties for Lil Wayne (Q15615)..\n",
      "Fetching quantity properties for Maroon 5 (Q182223)..\n",
      "Fetching quantity properties for Adele (Q23215)..\n",
      "Fetching quantity properties for Red Hot Chili Peppers (Q10708)..\n",
      "Fetching quantity properties for Fleetwood Mac (Q106648)..\n",
      "Fetching quantity properties for Bon Jovi (Q259254)..\n",
      "Fetching quantity properties for Rod Stewart (Q182655)..\n",
      "Fetching quantity properties for Bee Gees (Q133405)..\n",
      "Fetching quantity properties for Nicki Minaj (Q162202)..\n",
      "Fetching quantity properties for Coldplay (Q45188)..\n",
      "Fetching quantity properties for Linkin Park (Q261)..\n",
      "Fetching quantity properties for P!nk (Q160009)..\n",
      "Fetching quantity properties for Britney Spears (Q11975)..\n",
      "Fetching quantity properties for Shania Twain (Q131433)..\n",
      "Fetching quantity properties for Guns N' Roses (Q11895)..\n",
      "Fetching quantity properties for Backstreet Boys (Q17140)..\n",
      "Fetching quantity properties for Eric Clapton (Q48187)..\n",
      "Fetching quantity properties for Neil Diamond (Q294531)..\n",
      "Fetching quantity properties for Prince (Q2747456)..\n",
      "Fetching quantity properties for Journey (Q61509)..\n",
      "Fetching quantity properties for Paul McCartney (Q2599)..\n",
      "Fetching quantity properties for Janet Jackson (Q131324)..\n",
      "Fetching quantity properties for Kenny Rogers (Q217160)..\n",
      "Fetching quantity properties for Santana (Q873384)..\n",
      "Fetching quantity properties for George Michael (Q130311)..\n",
      "Fetching quantity properties for Dire Straits (Q50040)..\n",
      "Fetching quantity properties for The Doors (Q45354)..\n",
      "Fetching quantity properties for Foreigner (Q473741)..\n",
      "Fetching quantity properties for Chicago (Q371938)..\n",
      "Fetching quantity properties for Bob Dylan (Q392)..\n",
      "Fetching quantity properties for Carpenters (Q223495)..\n",
      "Fetching quantity properties for Meat Loaf (Q152929)..\n",
      "Fetching quantity properties for Cher (Q3286)..\n",
      "Fetching quantity properties for Def Leppard (Q182890)..\n",
      "Fetching quantity properties for Genesis (Q9184)..\n",
      "Fetching quantity properties for David Bowie (Q5383)..\n",
      "Fetching quantity properties for Stevie Wonder (Q714)..\n",
      "Fetching quantity properties for James Taylor (Q310300)..\n",
      "Fetching quantity properties for Tina Turner (Q131814)..\n",
      "Fetching quantity properties for Olivia Newton-John (Q185165)..\n",
      "Fetching quantity properties for Linda Ronstadt (Q229375)..\n",
      "Fetching quantity properties for The Beach Boys (Q183048)..\n",
      "Fetching quantity properties for Donna Summer (Q908933)..\n",
      "Fetching quantity properties for Alicia Keys (Q121507)..\n",
      "Fetching quantity properties for Christina Aguilera (Q41594)..\n",
      "Fetching quantity properties for Lionel Richie (Q26695)..\n",
      "Fetching quantity properties for Johnny Cash (Q42775)..\n",
      "Fetching quantity properties for Justin Timberlake (Q43432)..\n",
      "Fetching quantity properties for Ariana Grande (Q151892)..\n",
      "Fetching quantity properties for R.E.M. (Q134969)..\n",
      "Fetching quantity properties for Post Malone (Q21621919)..\n",
      "Fetching quantity properties for Flo Rida (Q213538)..\n",
      "Fetching quantity properties for Usher (Q165911)..\n",
      "Fetching quantity properties for Shakira (Q34424)..\n",
      "Fetching quantity properties for Tim McGraw (Q356487)..\n",
      "Fetching quantity properties for The Black Eyed Peas (Q134541)..\n",
      "Fetching quantity properties for Van Halen (Q190155)..\n",
      "Fetching quantity properties for Tom Petty (Q311655)..\n",
      "Fetching quantity properties for The Weeknd (Q2121062)..\n",
      "Fetching quantity properties for Imagine Dragons (Q391348)..\n",
      "Fetching quantity properties for 2Pac (Q6107)..\n",
      "Fetching quantity properties for R. Kelly (Q273055)..\n",
      "Fetching quantity properties for Nirvana (Q11649)..\n",
      "Fetching quantity properties for Bob Seger (Q364131)..\n",
      "Fetching quantity properties for Kenny G (Q295777)..\n",
      "Fetching quantity properties for Green Day (Q47871)..\n",
      "Fetching quantity properties for Enya (Q38257)..\n",
      "Fetching quantity properties for Bryan Adams (Q482907)..\n",
      "Fetching quantity properties for The Police (Q178095)..\n",
      "Fetching quantity properties for Gloria Estefan (Q184697)..\n",
      "Fetching quantity properties for Barry Manilow (Q302762)..\n",
      "Fetching quantity properties for Aretha Franklin (Q125121)..\n"
     ]
    }
   ],
   "source": [
    "# dictionary that maps the platform id to the platform name\n",
    "\n",
    "\n",
    "def send_amount_request(artist_uri,properties,repo):\n",
    "    \n",
    "    results_dict = {v: [] for k, v in properties.items()}\n",
    "    # Madonna's Wikidata item\n",
    "    item = pywikibot.ItemPage(repo, artist_uri)\n",
    "    \n",
    "    # Fetch the item's data\n",
    "    item.get()\n",
    "\n",
    "    # Iterate through the specified properties\n",
    "    for prop in properties:\n",
    "        if prop in item.claims:\n",
    "            #print(f\"{properties[prop]}:\")\n",
    "            for claim in item.claims[prop]:\n",
    "                # The target is the family member's item\n",
    "                target = claim.getTarget()\n",
    "                amount = target.amount\n",
    "                \n",
    "                \n",
    "                \n",
    "                #if isinstance(target, pywikibot.ItemPage):       \n",
    "                #target.get()\n",
    "                #print(f\"  {target.labels['en']}\")\n",
    "                \n",
    "                if prop == 'P8687':\n",
    "                    platformId_uri = claim.toJSON()['qualifiers-order'][0]\n",
    "                    \n",
    "                    #print('platformId_uri:',platformId_uri, 'amount:',amount)\n",
    "                    \n",
    "                    results_dict[properties[prop]].append([platformId_uri,amount])\n",
    "                else:\n",
    "                    results_dict[properties[prop]].append(amount)\n",
    "\n",
    "                        \n",
    "    return results_dict  \n",
    "\n",
    "# finding Quantity data features\n",
    "# properties that i want to extract per Artist\n",
    "properties_quantity = {\n",
    "        'P8687' : 'socialMediaFollowers',\n",
    "        'P1971': 'numberOfChildren'\n",
    "    }\n",
    "\n",
    "celebrity_quantity = {}\n",
    "# Iterate over each celebrity and fetch their relatives\n",
    "for celebrity, celebrity_uri in celebrity_uri_dict.items():\n",
    "    print(f\"Fetching quantity properties for {celebrity} ({celebrity_uri})..\")\n",
    "    results = send_amount_request(celebrity_uri,properties_quantity,repo)\n",
    "    #print(results)\n",
    "    #print('*'*50)\n",
    "    celebrity_quantity[celebrity] = results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T17:15:52.156930200Z",
     "start_time": "2024-03-17T17:14:58.810824300Z"
    }
   },
   "id": "a02e7529f9a6d7ad"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "platform_dict = {\n",
    "    'P2397': 'Youtube',\n",
    "    'P6552': 'Twitter/X'\n",
    "\n",
    "}\n",
    "\n",
    "def extract_most_recent_follows(celebrity_quantity, celebrity, platform_dict):\n",
    "\n",
    "    # Initialize variables to store the max values for P6552 and P585\n",
    "    max_P6552 = None\n",
    "    max_P2397 = None\n",
    "    \n",
    "    # Filter and find max for P6552\n",
    "    filtered_P6552 = [follower for follower in celebrity_quantity[celebrity]['socialMediaFollowers'] if follower[0] == 'P6552']\n",
    "    if filtered_P6552:\n",
    "        max_P6552 = max(filtered_P6552, key=lambda x: x[1])\n",
    "    \n",
    "    # Filter and find max for P585\n",
    "    filtered_P2397 = [follower for follower in celebrity_quantity[celebrity]['socialMediaFollowers'] if follower[0] == 'P2397']\n",
    "    if filtered_P2397:\n",
    "        max_P2397 = max(filtered_P2397, key=lambda x: x[1])\n",
    "\n",
    "    \n",
    "    # Update the celebrity_quantity dictionary to only include these maximum sublists for P6552 and P585\n",
    "    celebrity_quantity[celebrity]['mostRecentSocialMediaFollowers'] = {\n",
    "        platform_dict['P6552']: max_P6552,\n",
    "         platform_dict['P2397']: max_P2397\n",
    "    }\n",
    "    \n",
    "\n",
    "for celebrity in celebrity_quantity:\n",
    "    extract_most_recent_follows(celebrity_quantity, celebrity, platform_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T17:43:10.428120400Z",
     "start_time": "2024-03-17T17:43:10.368936200Z"
    }
   },
   "id": "255bd7e81812523f"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "celebrity_quantity_df = pd.DataFrame(celebrity_quantity).T\n",
    "celebrity_quantity_df.drop(columns=['socialMediaFollowers'], inplace=True)\n",
    "#celebrity_quantity_df.to_csv('Data//celebrity_quantity(children&followers).csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T17:43:12.100281100Z",
     "start_time": "2024-03-17T17:43:11.994874400Z"
    }
   },
   "id": "81f3f0bcc67d0133"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "celebrity_quantity_df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0abc71494cbb285"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danpa\\AppData\\Local\\Temp\\ipykernel_22628\\81398603.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "C:\\Users\\danpa\\AppData\\Local\\Temp\\ipykernel_22628\\81398603.py:6: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  charts10_df = pd.read_csv('Data//charts10.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sales_df = pd.read_csv('Data//best_selling_artists.csv')\n",
    "quantity_df = pd.read_csv('Data//celebrity_quantity(children&followers).csv')\n",
    "relatives_label_df = pd.read_csv('Data//celebrity_relatives&label.csv')\n",
    "charts10_df = pd.read_csv('Data//charts10.csv')\n",
    "artist_public_image_df = pd.read_csv('Data//artist_public_image.csv')\n",
    "quantity_df.rename(columns={'Unnamed: 0': 'Artist'}, inplace=True)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:45:38.025418200Z",
     "start_time": "2024-03-23T15:45:35.812067600Z"
    }
   },
   "id": "cdebaf21b1c1d9ce"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "  Artist numberOfChildren                     mostRecentSocialMediaFollowers\n4  Queen               []  {'Twitter/X': ['P6552', Decimal('2195409')], '...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Artist</th>\n      <th>numberOfChildren</th>\n      <th>mostRecentSocialMediaFollowers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>Queen</td>\n      <td>[]</td>\n      <td>{'Twitter/X': ['P6552', Decimal('2195409')], '...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantity_df.loc[relatives_label_df['Artist'] == 'Queen']\n",
    "\n",
    "\n",
    "# change queen(band) to queen"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:09:09.614949300Z",
     "start_time": "2024-03-23T16:09:09.577998Z"
    }
   },
   "id": "4fda5b7711e7c5b3"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "quantity_df['Artist'] = quantity_df['Artist'].replace({'Queen(band)': 'Queen'})\n",
    "relatives_label_df['Artist'] = relatives_label_df['Artist'].replace({'Queen(band)': 'Queen'})\n",
    "\n",
    "\n",
    "sales_df['Artist'] = sales_df['Artist'].replace({'Beyoncé': 'Beyonce', 'Jay-Z': 'Jay Z', 'Pink': 'P!nk', 'B\\'z': 'Bz', 'Julio Iglesias': 'Julio Iglesias Jr.', 'The Carpenters': 'Carpenters', 'Ayumi Hamasaki': 'Hamasaki Ayumi', 'Johnny Hallyday': 'Hallyday Johnny', 'Tupac Shakur': '2Pac', 'Bob Marley': 'Bob Marley & The Wailers'})\n",
    "\n",
    "artist_public_image_df['Artist'] = artist_public_image_df['Artist'].replace({'Beyoncé': 'Beyonce', 'Jay-Z': 'Jay Z', 'Pink': 'P!nk', 'B\\'z': 'Bz', 'Julio Iglesias': 'Julio Iglesias Jr.', 'The Carpenters': 'Carpenters', 'Ayumi Hamasaki': 'Hamasaki Ayumi', 'Johnny Hallyday': 'Hallyday Johnny', 'Tupac Shakur': '2Pac', 'Bob Marley': 'Bob Marley & The Wailers'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:08:27.756396400Z",
     "start_time": "2024-03-23T16:08:27.695074300Z"
    }
   },
   "id": "aac956d5d59803d0"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "             date  rank                            song Artist  last-week  \\\n9239   1976-04-17    10               Bohemian Rhapsody  Queen       12.0   \n9248   1976-04-24     9               Bohemian Rhapsody  Queen       10.0   \n9258   1976-05-01     9               Bohemian Rhapsody  Queen        9.0   \n10149  1978-01-14    10            We Are The Champions  Queen       13.0   \n10157  1978-01-21     8            We Are The Champions  Queen       10.0   \n10165  1978-01-28     6            We Are The Champions  Queen        8.0   \n10173  1978-02-04     4            We Are The Champions  Queen        6.0   \n10183  1978-02-11     4            We Are The Champions  Queen        4.0   \n10193  1978-02-18     4            We Are The Champions  Queen        4.0   \n10206  1978-02-25     7            We Are The Champions  Queen        4.0   \n11207  1980-01-26     8  Crazy Little Thing Called Love  Queen       18.0   \n11214  1980-02-02     5  Crazy Little Thing Called Love  Queen        8.0   \n11224  1980-02-09     5  Crazy Little Thing Called Love  Queen        5.0   \n11231  1980-02-16     2  Crazy Little Thing Called Love  Queen        5.0   \n11240  1980-02-23     1  Crazy Little Thing Called Love  Queen        2.0   \n11250  1980-03-01     1  Crazy Little Thing Called Love  Queen        1.0   \n11260  1980-03-08     1  Crazy Little Thing Called Love  Queen        1.0   \n11270  1980-03-15     1  Crazy Little Thing Called Love  Queen        1.0   \n11282  1980-03-22     3  Crazy Little Thing Called Love  Queen        1.0   \n11292  1980-03-29     3  Crazy Little Thing Called Love  Queen        3.0   \n11303  1980-04-05     4  Crazy Little Thing Called Love  Queen        3.0   \n11317  1980-04-12     8  Crazy Little Thing Called Love  Queen        4.0   \n11538  1980-09-13     9      Another One Bites The Dust  Queen       23.0   \n11542  1980-09-20     3      Another One Bites The Dust  Queen        9.0   \n11552  1980-09-27     3      Another One Bites The Dust  Queen        3.0   \n11560  1980-10-04     1      Another One Bites The Dust  Queen        3.0   \n11570  1980-10-11     1      Another One Bites The Dust  Queen        1.0   \n11580  1980-10-18     1      Another One Bites The Dust  Queen        1.0   \n11591  1980-10-25     2      Another One Bites The Dust  Queen        1.0   \n11601  1980-11-01     2      Another One Bites The Dust  Queen        2.0   \n11613  1980-11-08     4      Another One Bites The Dust  Queen        2.0   \n11623  1980-11-15     4      Another One Bites The Dust  Queen        4.0   \n11633  1980-11-22     4      Another One Bites The Dust  Queen        4.0   \n11643  1980-11-29     4      Another One Bites The Dust  Queen        4.0   \n11652  1980-12-06     3      Another One Bites The Dust  Queen        4.0   \n11662  1980-12-13     3      Another One Bites The Dust  Queen        3.0   \n11676  1980-12-20     7      Another One Bites The Dust  Queen        3.0   \n17579  1992-04-11    10               Bohemian Rhapsody  Queen       24.0   \n17583  1992-04-18     4               Bohemian Rhapsody  Queen       10.0   \n17593  1992-04-25     4               Bohemian Rhapsody  Queen        4.0   \n17603  1992-05-02     4               Bohemian Rhapsody  Queen        4.0   \n17611  1992-05-09     2               Bohemian Rhapsody  Queen        4.0   \n17622  1992-05-16     3               Bohemian Rhapsody  Queen        2.0   \n17634  1992-05-23     5               Bohemian Rhapsody  Queen        3.0   \n17648  1992-05-30     9               Bohemian Rhapsody  Queen        5.0   \n\n       peak-rank  weeks-on-board  Artists1  Artists2  Artists3  Artists4  \\\n9239          10              16       NaN       NaN       NaN       NaN   \n9248           9              17       NaN       NaN       NaN       NaN   \n9258           9              18       NaN       NaN       NaN       NaN   \n10149         10              13       NaN       NaN       NaN       NaN   \n10157          8              14       NaN       NaN       NaN       NaN   \n10165          6              15       NaN       NaN       NaN       NaN   \n10173          4              16       NaN       NaN       NaN       NaN   \n10183          4              17       NaN       NaN       NaN       NaN   \n10193          4              18       NaN       NaN       NaN       NaN   \n10206          4              19       NaN       NaN       NaN       NaN   \n11207          8               6       NaN       NaN       NaN       NaN   \n11214          5               7       NaN       NaN       NaN       NaN   \n11224          5               8       NaN       NaN       NaN       NaN   \n11231          2               9       NaN       NaN       NaN       NaN   \n11240          1              10       NaN       NaN       NaN       NaN   \n11250          1              11       NaN       NaN       NaN       NaN   \n11260          1              12       NaN       NaN       NaN       NaN   \n11270          1              13       NaN       NaN       NaN       NaN   \n11282          1              14       NaN       NaN       NaN       NaN   \n11292          1              15       NaN       NaN       NaN       NaN   \n11303          1              16       NaN       NaN       NaN       NaN   \n11317          1              17       NaN       NaN       NaN       NaN   \n11538          9               5       NaN       NaN       NaN       NaN   \n11542          3               6       NaN       NaN       NaN       NaN   \n11552          3               7       NaN       NaN       NaN       NaN   \n11560          1               8       NaN       NaN       NaN       NaN   \n11570          1               9       NaN       NaN       NaN       NaN   \n11580          1              10       NaN       NaN       NaN       NaN   \n11591          1              11       NaN       NaN       NaN       NaN   \n11601          1              12       NaN       NaN       NaN       NaN   \n11613          1              13       NaN       NaN       NaN       NaN   \n11623          1              14       NaN       NaN       NaN       NaN   \n11633          1              15       NaN       NaN       NaN       NaN   \n11643          1              16       NaN       NaN       NaN       NaN   \n11652          1              17       NaN       NaN       NaN       NaN   \n11662          1              18       NaN       NaN       NaN       NaN   \n11676          1              19       NaN       NaN       NaN       NaN   \n17579          9              28       NaN       NaN       NaN       NaN   \n17583          4              29       NaN       NaN       NaN       NaN   \n17593          4              30       NaN       NaN       NaN       NaN   \n17603          4              31       NaN       NaN       NaN       NaN   \n17611          2              32       NaN       NaN       NaN       NaN   \n17622          2              33       NaN       NaN       NaN       NaN   \n17634          2              34       NaN       NaN       NaN       NaN   \n17648          2              35       NaN       NaN       NaN       NaN   \n\n       Artists5 Artist1 Artist2 Artist3 Artist4 Artist5  \n9239        NaN   Queen     NaN     NaN     NaN     NaN  \n9248        NaN   Queen     NaN     NaN     NaN     NaN  \n9258        NaN   Queen     NaN     NaN     NaN     NaN  \n10149       NaN   Queen     NaN     NaN     NaN     NaN  \n10157       NaN   Queen     NaN     NaN     NaN     NaN  \n10165       NaN   Queen     NaN     NaN     NaN     NaN  \n10173       NaN   Queen     NaN     NaN     NaN     NaN  \n10183       NaN   Queen     NaN     NaN     NaN     NaN  \n10193       NaN   Queen     NaN     NaN     NaN     NaN  \n10206       NaN   Queen     NaN     NaN     NaN     NaN  \n11207       NaN   Queen     NaN     NaN     NaN     NaN  \n11214       NaN   Queen     NaN     NaN     NaN     NaN  \n11224       NaN   Queen     NaN     NaN     NaN     NaN  \n11231       NaN   Queen     NaN     NaN     NaN     NaN  \n11240       NaN   Queen     NaN     NaN     NaN     NaN  \n11250       NaN   Queen     NaN     NaN     NaN     NaN  \n11260       NaN   Queen     NaN     NaN     NaN     NaN  \n11270       NaN   Queen     NaN     NaN     NaN     NaN  \n11282       NaN   Queen     NaN     NaN     NaN     NaN  \n11292       NaN   Queen     NaN     NaN     NaN     NaN  \n11303       NaN   Queen     NaN     NaN     NaN     NaN  \n11317       NaN   Queen     NaN     NaN     NaN     NaN  \n11538       NaN   Queen     NaN     NaN     NaN     NaN  \n11542       NaN   Queen     NaN     NaN     NaN     NaN  \n11552       NaN   Queen     NaN     NaN     NaN     NaN  \n11560       NaN   Queen     NaN     NaN     NaN     NaN  \n11570       NaN   Queen     NaN     NaN     NaN     NaN  \n11580       NaN   Queen     NaN     NaN     NaN     NaN  \n11591       NaN   Queen     NaN     NaN     NaN     NaN  \n11601       NaN   Queen     NaN     NaN     NaN     NaN  \n11613       NaN   Queen     NaN     NaN     NaN     NaN  \n11623       NaN   Queen     NaN     NaN     NaN     NaN  \n11633       NaN   Queen     NaN     NaN     NaN     NaN  \n11643       NaN   Queen     NaN     NaN     NaN     NaN  \n11652       NaN   Queen     NaN     NaN     NaN     NaN  \n11662       NaN   Queen     NaN     NaN     NaN     NaN  \n11676       NaN   Queen     NaN     NaN     NaN     NaN  \n17579       NaN   Queen     NaN     NaN     NaN     NaN  \n17583       NaN   Queen     NaN     NaN     NaN     NaN  \n17593       NaN   Queen     NaN     NaN     NaN     NaN  \n17603       NaN   Queen     NaN     NaN     NaN     NaN  \n17611       NaN   Queen     NaN     NaN     NaN     NaN  \n17622       NaN   Queen     NaN     NaN     NaN     NaN  \n17634       NaN   Queen     NaN     NaN     NaN     NaN  \n17648       NaN   Queen     NaN     NaN     NaN     NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>rank</th>\n      <th>song</th>\n      <th>Artist</th>\n      <th>last-week</th>\n      <th>peak-rank</th>\n      <th>weeks-on-board</th>\n      <th>Artists1</th>\n      <th>Artists2</th>\n      <th>Artists3</th>\n      <th>Artists4</th>\n      <th>Artists5</th>\n      <th>Artist1</th>\n      <th>Artist2</th>\n      <th>Artist3</th>\n      <th>Artist4</th>\n      <th>Artist5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9239</th>\n      <td>1976-04-17</td>\n      <td>10</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>12.0</td>\n      <td>10</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9248</th>\n      <td>1976-04-24</td>\n      <td>9</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>10.0</td>\n      <td>9</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9258</th>\n      <td>1976-05-01</td>\n      <td>9</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>9.0</td>\n      <td>9</td>\n      <td>18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10149</th>\n      <td>1978-01-14</td>\n      <td>10</td>\n      <td>We Are The Champions</td>\n      <td>Queen</td>\n      <td>13.0</td>\n      <td>10</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10157</th>\n      <td>1978-01-21</td>\n      <td>8</td>\n      <td>We Are The Champions</td>\n      <td>Queen</td>\n      <td>10.0</td>\n      <td>8</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10165</th>\n      <td>1978-01-28</td>\n      <td>6</td>\n      <td>We Are The Champions</td>\n      <td>Queen</td>\n      <td>8.0</td>\n      <td>6</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10173</th>\n      <td>1978-02-04</td>\n      <td>4</td>\n      <td>We Are The Champions</td>\n      <td>Queen</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10183</th>\n      <td>1978-02-11</td>\n      <td>4</td>\n      <td>We Are The Champions</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10193</th>\n      <td>1978-02-18</td>\n      <td>4</td>\n      <td>We Are The Champions</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10206</th>\n      <td>1978-02-25</td>\n      <td>7</td>\n      <td>We Are The Champions</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>19</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11207</th>\n      <td>1980-01-26</td>\n      <td>8</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>18.0</td>\n      <td>8</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11214</th>\n      <td>1980-02-02</td>\n      <td>5</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>8.0</td>\n      <td>5</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11224</th>\n      <td>1980-02-09</td>\n      <td>5</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11231</th>\n      <td>1980-02-16</td>\n      <td>2</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>5.0</td>\n      <td>2</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11240</th>\n      <td>1980-02-23</td>\n      <td>1</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11250</th>\n      <td>1980-03-01</td>\n      <td>1</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11260</th>\n      <td>1980-03-08</td>\n      <td>1</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>12</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11270</th>\n      <td>1980-03-15</td>\n      <td>1</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11282</th>\n      <td>1980-03-22</td>\n      <td>3</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11292</th>\n      <td>1980-03-29</td>\n      <td>3</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11303</th>\n      <td>1980-04-05</td>\n      <td>4</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11317</th>\n      <td>1980-04-12</td>\n      <td>8</td>\n      <td>Crazy Little Thing Called Love</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11538</th>\n      <td>1980-09-13</td>\n      <td>9</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>23.0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11542</th>\n      <td>1980-09-20</td>\n      <td>3</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>9.0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11552</th>\n      <td>1980-09-27</td>\n      <td>3</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>3.0</td>\n      <td>3</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11560</th>\n      <td>1980-10-04</td>\n      <td>1</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11570</th>\n      <td>1980-10-11</td>\n      <td>1</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11580</th>\n      <td>1980-10-18</td>\n      <td>1</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11591</th>\n      <td>1980-10-25</td>\n      <td>2</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11601</th>\n      <td>1980-11-01</td>\n      <td>2</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>12</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11613</th>\n      <td>1980-11-08</td>\n      <td>4</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11623</th>\n      <td>1980-11-15</td>\n      <td>4</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11633</th>\n      <td>1980-11-22</td>\n      <td>4</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11643</th>\n      <td>1980-11-29</td>\n      <td>4</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11652</th>\n      <td>1980-12-06</td>\n      <td>3</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11662</th>\n      <td>1980-12-13</td>\n      <td>3</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11676</th>\n      <td>1980-12-20</td>\n      <td>7</td>\n      <td>Another One Bites The Dust</td>\n      <td>Queen</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>19</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17579</th>\n      <td>1992-04-11</td>\n      <td>10</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>24.0</td>\n      <td>9</td>\n      <td>28</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17583</th>\n      <td>1992-04-18</td>\n      <td>4</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>10.0</td>\n      <td>4</td>\n      <td>29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17593</th>\n      <td>1992-04-25</td>\n      <td>4</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17603</th>\n      <td>1992-05-02</td>\n      <td>4</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17611</th>\n      <td>1992-05-09</td>\n      <td>2</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>4.0</td>\n      <td>2</td>\n      <td>32</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17622</th>\n      <td>1992-05-16</td>\n      <td>3</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>33</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17634</th>\n      <td>1992-05-23</td>\n      <td>5</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>3.0</td>\n      <td>2</td>\n      <td>34</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17648</th>\n      <td>1992-05-30</td>\n      <td>9</td>\n      <td>Bohemian Rhapsody</td>\n      <td>Queen</td>\n      <td>5.0</td>\n      <td>2</td>\n      <td>35</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Queen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:04:44.011267300Z",
     "start_time": "2024-03-23T16:04:43.860551400Z"
    }
   },
   "id": "f19e28b6ca12c403"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "sales_df.to_csv('Data//best_selling_artists.csv', index=False)\n",
    "artist_public_image_df.to_csv('Data//artist_public_image.csv', index=False)\n",
    "relatives_label_df.to_csv('Data//celebrity_relatives&label.csv', index=False)\n",
    "quantity_df.to_csv('Data//celebrity_quantity(children&followers).csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:09:13.084770400Z",
     "start_time": "2024-03-23T16:09:13.001843200Z"
    }
   },
   "id": "2f912d3501ece82f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
